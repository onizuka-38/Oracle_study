# check_env.py
from dotenv import load_dotenv
import os
import psycopg2
from huggingface_hub import InferenceClient
from langchain_openai import OpenAIEmbeddings

print("ğŸ” í™˜ê²½ ë³€ìˆ˜ í™•ì¸ ì¤‘...\n")

# 1ï¸âƒ£ .env ë¡œë“œ
load_dotenv()

# 2ï¸âƒ£ í™˜ê²½ ë³€ìˆ˜ ì½ê¸°
openai_key = os.getenv("OPENAI_API_KEY")
hf_token = os.getenv("HUGGINGFACEHUB_API_TOKEN")

print(f"âœ… OPENAI_API_KEY: {'OK' if openai_key else 'âŒ ì—†ìŒ'}")
print(f"âœ… HUGGINGFACEHUB_API_TOKEN: {'OK' if hf_token else 'âŒ ì—†ìŒ'}")

# 3ï¸âƒ£ Hugging Face ì—°ê²° í…ŒìŠ¤íŠ¸
if hf_token:
    try:
        client = InferenceClient(token=hf_token)
        result = client.text_generation(
            model="google/flan-t5-base",
            prompt="í•œ ì¤„ë¡œ ìš”ì•½í•´ì¤˜: ì¸ê³µì§€ëŠ¥ì´ë€ ë¬´ì—‡ì¸ê°€?",
            max_new_tokens=30
        )
        print("ğŸ¤– Hugging Face ì‘ë‹µ:", result.strip())
    except Exception as e:
        print("âŒ Hugging Face ì˜¤ë¥˜:", e)

# 4ï¸âƒ£ OpenAI Embedding í…ŒìŠ¤íŠ¸
if openai_key:
    try:
        emb = OpenAIEmbeddings(model="text-embedding-3-small")
        vector = emb.embed_query("í…ŒìŠ¤íŠ¸ ë¬¸ì¥")
        print(f"ğŸ§  OpenAI ì„ë² ë”© ê¸¸ì´: {len(vector)}")
    except Exception as e:
        print("âŒ OpenAI ì„ë² ë”© ì˜¤ë¥˜:", e)

# 5ï¸âƒ£ PostgreSQL ì—°ê²° í…ŒìŠ¤íŠ¸
try:
    conn = psycopg2.connect(
        host="127.0.0.1",
        port=5432,
        database="testdb",
        user="test",
        password="5748"
    )
    cur = conn.cursor()
    cur.execute("SELECT version();")
    print("ğŸ—„ï¸ PostgreSQL ì—°ê²° ì„±ê³µ:", cur.fetchone()[0])
    cur.execute("SELECT * FROM pg_extension WHERE extname='vector';")
    print("ğŸ“¦ pgvector ìƒíƒœ:", cur.fetchone())
    cur.close()
    conn.close()
except Exception as e:
    print("âŒ PostgreSQL ì—°ê²° ì˜¤ë¥˜:", e)

print("\nâœ… í™˜ê²½ ì ê²€ ì™„ë£Œ.")
