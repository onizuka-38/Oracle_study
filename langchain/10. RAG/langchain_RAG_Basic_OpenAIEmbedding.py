import psycopg
from dotenv import load_dotenv
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_postgres import PGVector
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough

load_dotenv()

print("=" * 80)
print("Langchain RAG 8ë‹¨ê³„ í”„ë¡œì„¸ìŠ¤")
print("=" * 80)

# ============================================================
# 1ë‹¨ê³„: ë¬¸ì„œ ë¡œë“œ (Document Loader)
# - ì™¸ë¶€ ë°ì´í„° ì†ŒìŠ¤ì—ì„œ ë¬¸ì„œë¥¼ ë¡œë“œ
# ============================================================
print("\n[1ë‹¨ê³„] ë¬¸ì„œ ë¡œë“œ (Document Loader)")
print("-" * 80)

FILE_PATH = "9. Retriever/data/SPRi AI Brief_10ì›”í˜¸_ì‚°ì—…ë™í–¥_1002_F.pdf"
loader = PyPDFLoader(FILE_PATH)

# PDF íŒŒì¼ì„ í˜ì´ì§€ë³„ë¡œ ë¡œë“œ
documents = loader.load()

print(f"ì´ {len(documents)} í˜ì´ì§€ ë¡œë“œ ì™„ë£Œ")
print(f"ì²« í˜ì´ì§€ ë¯¸ë¦¬ë³´ê¸°: {documents[0].page_content[:100]}...")

# ============================================================
# 2ë‹¨ê³„: í…ìŠ¤íŠ¸ ë¶„í•  (Text Splitter)
# - ë¡œë“œëœ ë¬¸ì„œë¥¼ ì²˜ë¦¬ ê°€ëŠ¥í•œ ì‘ì€ ë‹¨ìœ„(ì²­í¬)ë¡œ ë¶„í• 
# ============================================================
print("\n[2ë‹¨ê³„] í…ìŠ¤íŠ¸ ë¶„í•  (Text Splitter)")
print("-" * 80)

# 1000ì ë‹¨ìœ„ë¡œ ë¶„í• , 100ì ì¤‘ë³µ(ì˜¤ë²„ë©)
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000,      # ê° ì²­í¬ì˜ í¬ê¸°
    chunk_overlap=100,    # ì²­í¬ ê°„ ì¤‘ë³µë˜ëŠ” ë¶€ë¶„
    length_function=len,  # ê¸¸ì´ ì¸¡ì • í•¨ìˆ˜
)

# ë¬¸ì„œë¥¼ ì²­í¬ë¡œ ë¶„í• 
splits = text_splitter.split_documents(documents)

print(f"ì´ {len(splits)}ê°œì˜ ì²­í¬ë¡œ ë¶„í•  ì™„ë£Œ")
print(f"ì²« ë²ˆì§¸ ì²­í¬: {splits[0].page_content[:150]}...")

# ============================================================
# 3ë‹¨ê³„: ì„ë² ë”© (Embedding)
# - ê° í…ìŠ¤íŠ¸ ì²­í¬ë¥¼ ë²¡í„°ë¡œ ë³€í™˜
# ============================================================
print("\n[3ë‹¨ê³„] ì„ë² ë”© (Embedding)")
print("-" * 80)

# OpenAI ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
embeddings_model = OpenAIEmbeddings(
    model="text-embedding-3-small"
)

# í…ŒìŠ¤íŠ¸: ìƒ˜í”Œ í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜
sample_text = "ìƒì„±í˜• AI ê¸°ìˆ  ë™í–¥"
sample_vector = embeddings_model.embed_query(sample_text)

print(f"ì„ë² ë”© ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ")
print(f"ë²¡í„° ì°¨ì›: {len(sample_vector)}ì°¨ì›")
print(f"ìƒ˜í”Œ ë²¡í„° (ì²˜ìŒ 5ê°œ): {sample_vector[:5]}")

# ============================================================
# 4ë‹¨ê³„: ë²¡í„°ìŠ¤í† ì–´ ì €ì¥ (Vector Store)
# - ì„ë² ë”©ëœ ë²¡í„°ë“¤ì„ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
# ============================================================
print("\n[4ë‹¨ê³„] ë²¡í„°ìŠ¤í† ì–´ ì €ì¥ (Vector Store)")
print("-" * 80)

# PostgreSQL ì—°ê²° ì„¤ì •
db_config = {
    'host': 'localhost',
    'port': 5432,
    'dbname': 'testdb',  # psycopgëŠ” dbname ì‚¬ìš©
    'user': 'test',
    'password': '5748'
}

# pgvector extension í™•ì¸
# PostgreSQLì—ì„œ ë²¡í„° ì—°ì‚°ì„ ê°€ëŠ¥í•˜ê²Œ í•˜ëŠ” í™•ì¥ ê¸°ëŠ¥
conn = None
try:
    conn = psycopg.connect(**db_config)
    cursor = conn.cursor()
    cursor.execute("CREATE EXTENSION IF NOT EXISTS vector;")
    conn.commit()
    cursor.close()
    print("pgvector extension í™•ì¸ ì™„ë£Œ")
except Exception as e:
    print(f"Extension ìƒì„± ì¤‘ ì—ëŸ¬: {e}")
finally:
    if conn:
        conn.close()

# PGVector ì—°ê²° ë¬¸ìì—´ ì‘ì„±
CONNECTION_STRING = f"postgresql+psycopg://{db_config['user']}:{db_config['password']}@{db_config['host']}:{db_config['port']}/{db_config['dbname']}"

# PGVectorë¡œ ë²¡í„° ì €ì¥
vectorstore = PGVector.from_documents(
    documents=splits,                    # ë¶„í• ëœ ë¬¸ì„œë“¤
    embedding=embeddings_model,          # ì„ë² ë”© ëª¨ë¸
    collection_name="rag_example",       # ì»¬ë ‰ì…˜ ì´ë¦„
    connection=CONNECTION_STRING,        # DB ì—°ê²°
    pre_delete_collection=True,          # ê¸°ì¡´ ë°ì´í„° ì‚­ì œ
)

print(f"ë²¡í„°ìŠ¤í† ì–´ì— {len(splits)}ê°œ ì²­í¬ ì €ì¥ ì™„ë£Œ")
print(f"ì»¬ë ‰ì…˜ ì´ë¦„: rag_example")

# ============================================================
# 5ë‹¨ê³„: ê²€ìƒ‰ê¸° (Retriever)
# - ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ë¬¸ì„œë¥¼ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê²€ìƒ‰
# ============================================================
print("\n[5ë‹¨ê³„] ê²€ìƒ‰ê¸° (Retriever)")
print("-" * 80)

# Retriever ìƒì„±
# search_type="similarity": ìœ ì‚¬ë„ ê¸°ë°˜ ê²€ìƒ‰
# search_kwargs={"k": 3}: ìƒìœ„ 3ê°œ ê²°ê³¼ ë°˜í™˜
retriever = vectorstore.as_retriever(
    search_type="similarity",
    search_kwargs={"k": 3}
)

# í…ŒìŠ¤íŠ¸ ê²€ìƒ‰
test_query = "ìƒì„±í˜• AIì˜ ìµœì‹  ê¸°ìˆ  ë™í–¥ì€?"
retrieved_docs = retriever.invoke(test_query)

print(f"ê²€ìƒ‰ê¸° ìƒì„± ì™„ë£Œ")
print(f"í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬: '{test_query}'")
print(f"ê²€ìƒ‰ëœ ë¬¸ì„œ: {len(retrieved_docs)}ê°œ")
print(f"ì²« ë²ˆì§¸ ê²°ê³¼: {retrieved_docs[0].page_content[:100]}...")

# ============================================================
# 6ë‹¨ê³„: í”„ë¡¬í”„íŠ¸ (Prompt)
# - ê²€ìƒ‰ëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ LLMì„ ìœ„í•œ ì§ˆë¬¸ êµ¬ì„±
# ============================================================
print("\n[6ë‹¨ê³„] í”„ë¡¬í”„íŠ¸ (Prompt)")
print("-" * 80)

# RAG í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ êµ¬ì„± (ê°œì„ ëœ ë²„ì „)
# {context}: ê²€ìƒ‰ëœ ë¬¸ì„œë“¤
# {question}: ì‚¬ìš©ì ì§ˆë¬¸
prompt_template = ChatPromptTemplate.from_messages([
    ("system", """ë‹¹ì‹ ì€ AI ê¸°ìˆ  ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì•„ë˜ ì œê³µëœ ë¬¸ë§¥(context)ì„ **ë°˜ë“œì‹œ ì°¸ê³ **í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.

ì¤‘ìš”:
1. ë¬¸ë§¥ì— ê´€ë ¨ ë‚´ìš©ì´ ìˆìœ¼ë©´ ê·¸ê²ƒì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.
2. ë¬¸ë§¥ì— ì—†ëŠ” ë‚´ìš©ë§Œ "ì œê³µëœ ë¬¸ì„œì—ì„œ í•´ë‹¹ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ë‹µë³€í•˜ì„¸ìš”.
3. ë‹µë³€ ì‹œ ë¬¸ë§¥ì˜ ì–´ëŠ ë¶€ë¶„ì„ ì°¸ê³ í–ˆëŠ”ì§€ ëª…ì‹œí•˜ì„¸ìš”.

ë¬¸ë§¥:
{context}
"""),
("human", "{question}")
])

print("í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„± ì™„ë£Œ")
print(f"ì‹œìŠ¤í…œ ì—­í• : AI ê¸°ìˆ  ì „ë¬¸ê°€")
print(f"í”„ë¡¬í”„íŠ¸ êµ¬ì¡°: ë¬¸ë§¥(context) + ì§ˆë¬¸(question)")

# ============================================================
# 7ë‹¨ê³„: LLM (Large Language Model)
# - êµ¬ì„±ëœ í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹µë³€ ìƒì„±
# ============================================================
print("\n[7ë‹¨ê³„] LLM (Large Language Model)")
print("-" * 80)

# ChatGPT ëª¨ë¸ ì´ˆê¸°í™”
llm = ChatOpenAI(
    model="gpt-4o-mini",  # ëª¨ë¸ ì„ íƒ
    temperature=0.5,         # ì°½ì˜ì„± ì¡°ì ˆ (0=ê²°ì •ì , 1=ì°½ì˜ì )
)

print("LLM ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ")
print(f"ëª¨ë¸: gpt-4o-mini")

# ============================================================
# 8ë‹¨ê³„: ì²´ì¸(Chain) ìƒì„±
# - ëª¨ë“  ê³¼ì •ì„ í•˜ë‚˜ì˜ íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ ì—°ê²°
# ============================================================
print("\n[8ë‹¨ê³„] ì²´ì¸(Chain) ìƒì„±")
print("-" * 80)

# ë¬¸ì„œë¥¼ ë¬¸ë§¥ìœ¼ë¡œ í¬ë§·íŒ…í•˜ëŠ” í•¨ìˆ˜
def format_docs(docs):
    """
    ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì„ ë²ˆí˜¸ì™€ êµ¬ë¶„ì„ ìœ¼ë¡œ í¬ë§·íŒ…
    - [ë¬¸ì„œ 1], [ë¬¸ì„œ 2] í˜•ì‹ìœ¼ë¡œ ë²ˆí˜¸ ë¶€ì—¬
    - --- êµ¬ë¶„ì„ ìœ¼ë¡œ ëª…í™•í•˜ê²Œ ë¶„ë¦¬
    """
    formatted = []
    for idx, doc in enumerate(docs, 1):
        formatted.append(f"[ë¬¸ì„œ {idx}]\n{doc.page_content}")
    return "\n\n---\n\n".join(formatted)

# RAG Chain êµ¬ì„±
# RunnablePassthrough(): ì…ë ¥ì„ ê·¸ëŒ€ë¡œ ì „ë‹¬
# retriever: ì§ˆë¬¸ìœ¼ë¡œ ë¬¸ì„œ ê²€ìƒ‰
# format_docs: ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
# prompt_template: í”„ë¡¬í”„íŠ¸ ìƒì„±
# llm: ë‹µë³€ ìƒì„±
# StrOutputParser(): ì¶œë ¥ì„ ë¬¸ìì—´ë¡œ íŒŒì‹±
rag_chain = (
    {
        "context": retriever | format_docs,  # ê²€ìƒ‰ â†’ í¬ë§·íŒ…
        "question": RunnablePassthrough()     # ì§ˆë¬¸ ê·¸ëŒ€ë¡œ ì „ë‹¬
    }
    | prompt_template   # í”„ë¡¬í”„íŠ¸ ìƒì„±
    | llm               # LLM ì‹¤í–‰
    | StrOutputParser() # ì¶œë ¥ íŒŒì‹±
)

print("RAG Chain ìƒì„± ì™„ë£Œ")
print("""
Chain êµ¬ì¡°:
   ì§ˆë¬¸ ì…ë ¥
      â†“
   [Retriever] ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰ (5ë‹¨ê³„)
      â†“
   [Format] ë¬¸ì„œë¥¼ ë¬¸ë§¥ìœ¼ë¡œ ë³€í™˜
      â†“
   [Prompt] í”„ë¡¬í”„íŠ¸ ìƒì„± (6ë‹¨ê³„)
      â†“
   [LLM] ë‹µë³€ ìƒì„± (7ë‹¨ê³„)
      â†“
   ìµœì¢… ë‹µë³€ ì¶œë ¥
""")

# ============================================================
# RAG ì‹¤í–‰ í…ŒìŠ¤íŠ¸
# ============================================================
print("\n" + "=" * 80)
print("RAG ì‹œìŠ¤í…œ ì‹¤í–‰ í…ŒìŠ¤íŠ¸")
print("=" * 80)

# ì§ˆë¬¸ ëª©ë¡
questions = [
    "ì¤‘êµ­ êµ­ë¬´ì›ì´ ë°œí‘œí•œ 'AI í”ŒëŸ¬ìŠ¤' ì •ì±…ì˜ 3ë‹¨ê³„ ì¤‘ì¥ê¸° ëª©í‘œëŠ” ë¬´ì—‡ì´ë©°, 6ëŒ€ í•µì‹¬ ì˜ì—­ì€ ì–´ë””ì¸ê°€ìš”?",
    "êµ¬ê¸€ì´ ê³µê°œí•œ ì´ë¯¸ì§€ í¸ì§‘ ëª¨ë¸ 'ì œë¯¸ë‚˜ì´ 2.5 í”Œë˜ì‹œ ì´ë¯¸ì§€'ì˜ ê°€ì¥ í° íŠ¹ì§•ì€ ë¬´ì—‡ì¸ê°€ìš”?",
    "ìŠ¤íƒ í¬ë“œ ëŒ€í•™ì˜ ì—°êµ¬ ê²°ê³¼, ìƒì„± AIì˜ í™•ì‚°ì´ ê²½ë ¥ ì´ˆê¸° ê·¼ë¡œìì˜ ê³ ìš©ì— ì–´ë–¤ ì˜í–¥ì„ ë¯¸ì¹˜ê³  ìˆë‚˜ìš”? "
]

for idx, question in enumerate(questions, 1):
    print(f"\n[ì§ˆë¬¸ {idx}] {question}")
    print("-" * 80)
    
    # RAG Chain ì‹¤í–‰
    answer = rag_chain.invoke(question)
    
    print(f"ğŸ’¬ ë‹µë³€:\n{answer}")
    print("-" * 80)

# ============================================================
# ëŒ€í™”í˜• RAG ì‹œìŠ¤í…œ
# ============================================================
print("\nëŒ€í™”í˜• RAG ì‹œìŠ¤í…œ ì‹œì‘")
print("ì¢…ë£Œí•˜ë ¤ë©´ 'quit' ë˜ëŠ” 'exit'ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
print("=" * 80)

while True:
    user_question = input("\nì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”: ").strip()
    
    if user_question.lower() in ['quit', 'exit', 'ì¢…ë£Œ']:
        print("\nRAG ì‹œìŠ¤í…œì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        break
    
    if not user_question:
        print("ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        continue
    
    try:
        print("\nğŸ” ë¬¸ì„œ ê²€ìƒ‰ ì¤‘...")
        answer = rag_chain.invoke(user_question)
        print(f"\në‹µë³€:\n{answer}")
        print("-" * 80)
    except Exception as e:
        print(f"\nì—ëŸ¬ ë°œìƒ: {e}")