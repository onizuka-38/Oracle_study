import psycopg
from dotenv import load_dotenv
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_postgres import PGVector
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_core.chat_history import BaseChatMessageHistory, InMemoryChatMessageHistory
from operator import itemgetter

load_dotenv()

print("=" * 80)
print("Langchain RAG 8ë‹¨ê³„ í”„ë¡œì„¸ìŠ¤ - ë©€í‹°í„´ ëŒ€í™”")
print("=" * 80)

# ============================================================
# 1ë‹¨ê³„: ë¬¸ì„œ ë¡œë“œ (Document Loader)
# - ì™¸ë¶€ ë°ì´í„° ì†ŒìŠ¤ì—ì„œ ë¬¸ì„œë¥¼ ë¡œë“œ
# ============================================================
print("\n[1ë‹¨ê³„] ë¬¸ì„œ ë¡œë“œ (Document Loader)")
print("-" * 80)

FILE_PATH = "9. Retriever/data/SPRi AI Brief_10ì›”í˜¸_ì‚°ì—…ë™í–¥_1002_F.pdf"
loader = PyPDFLoader(FILE_PATH)

# PDF íŒŒì¼ì„ í˜ì´ì§€ë³„ë¡œ ë¡œë“œ
documents = loader.load()

print(f"ì´ {len(documents)} í˜ì´ì§€ ë¡œë“œ ì™„ë£Œ")
print(f"ì²« í˜ì´ì§€ ë¯¸ë¦¬ë³´ê¸°: {documents[0].page_content[:100]}...")

# ============================================================
# 2ë‹¨ê³„: í…ìŠ¤íŠ¸ ë¶„í•  (Text Splitter)
# - ë¡œë“œëœ ë¬¸ì„œë¥¼ ì²˜ë¦¬ ê°€ëŠ¥í•œ ì‘ì€ ë‹¨ìœ„(ì²­í¬)ë¡œ ë¶„í• 
# ============================================================
print("\n[2ë‹¨ê³„] í…ìŠ¤íŠ¸ ë¶„í•  (Text Splitter)")
print("-" * 80)

# 1000ì ë‹¨ìœ„ë¡œ ë¶„í• , 100ì ì¤‘ë³µ(ì˜¤ë²„ë©)
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000,      # ê° ì²­í¬ì˜ í¬ê¸°
    chunk_overlap=100,    # ì²­í¬ ê°„ ì¤‘ë³µë˜ëŠ” ë¶€ë¶„
    length_function=len,  # ê¸¸ì´ ì¸¡ì • í•¨ìˆ˜
)

# ë¬¸ì„œë¥¼ ì²­í¬ë¡œ ë¶„í• 
splits = text_splitter.split_documents(documents)

print(f"ì´ {len(splits)}ê°œì˜ ì²­í¬ë¡œ ë¶„í•  ì™„ë£Œ")
print(f"ì²« ë²ˆì§¸ ì²­í¬: {splits[0].page_content[:150]}...")

# ============================================================
# 3ë‹¨ê³„: ì„ë² ë”© (Embedding)
# - ê° í…ìŠ¤íŠ¸ ì²­í¬ë¥¼ ë²¡í„°ë¡œ ë³€í™˜
# ============================================================
print("\n[3ë‹¨ê³„] ì„ë² ë”© (Embedding)")
print("-" * 80)

# OpenAI ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
embeddings_model = OpenAIEmbeddings(
    model="text-embedding-3-small"
)

# í…ŒìŠ¤íŠ¸: ìƒ˜í”Œ í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜
sample_text = "ìƒì„±í˜• AI ê¸°ìˆ  ë™í–¥"
sample_vector = embeddings_model.embed_query(sample_text)

print(f"ì„ë² ë”© ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ")
print(f"ë²¡í„° ì°¨ì›: {len(sample_vector)}ì°¨ì›")
print(f"ìƒ˜í”Œ ë²¡í„° (ì²˜ìŒ 5ê°œ): {sample_vector[:5]}")

# ============================================================
# 4ë‹¨ê³„: ë²¡í„°ìŠ¤í† ì–´ ì €ì¥ (Vector Store)
# - ì„ë² ë”©ëœ ë²¡í„°ë“¤ì„ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
# ============================================================
print("\n[4ë‹¨ê³„] ë²¡í„°ìŠ¤í† ì–´ ì €ì¥ (Vector Store)")
print("-" * 80)

# PostgreSQL ì—°ê²° ì„¤ì •
db_config = {
    'host': 'localhost',
    'port': 5432,
    'dbname': 'testdb',
    'user': 'test',
    'password': '5748'
}

# pgvector extension í™•ì¸
# PostgreSQLì—ì„œ ë²¡í„° ì—°ì‚°ì„ ê°€ëŠ¥í•˜ê²Œ í•˜ëŠ” í™•ì¥ ê¸°ëŠ¥
conn = None
try:
    conn = psycopg.connect(**db_config)
    cursor = conn.cursor()
    cursor.execute("CREATE EXTENSION IF NOT EXISTS vector;")
    conn.commit()
    cursor.close()
    print("pgvector extension í™•ì¸ ì™„ë£Œ")
except Exception as e:
    print(f"Extension ìƒì„± ì¤‘ ì—ëŸ¬: {e}")
finally:
    if conn:
        conn.close()

# PGVector ì—°ê²° ë¬¸ìì—´ ì§ì ‘ ì‘ì„±
CONNECTION_STRING = f"postgresql+psycopg://{db_config['user']}:{db_config['password']}@{db_config['host']}:{db_config['port']}/{db_config['dbname']}"

# PGVectorë¡œ ë²¡í„° ì €ì¥
vectorstore = PGVector.from_documents(
    documents=splits,                    # ë¶„í• ëœ ë¬¸ì„œë“¤
    embedding=embeddings_model,          # ì„ë² ë”© ëª¨ë¸
    collection_name="rag_example",       # ì»¬ë ‰ì…˜ ì´ë¦„
    connection=CONNECTION_STRING,        # DB ì—°ê²°
    pre_delete_collection=True,          # ê¸°ì¡´ ë°ì´í„° ì‚­ì œ
)

print(f"ë²¡í„°ìŠ¤í† ì–´ì— {len(splits)}ê°œ ì²­í¬ ì €ì¥ ì™„ë£Œ")
print(f"ì»¬ë ‰ì…˜ ì´ë¦„: rag_example")

# ============================================================
# 5ë‹¨ê³„: ê²€ìƒ‰ê¸° (Retriever)
# - ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ë¬¸ì„œë¥¼ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê²€ìƒ‰
# ============================================================
print("\n[5ë‹¨ê³„] ê²€ìƒ‰ê¸° (Retriever)")
print("-" * 80)

# Retriever ìƒì„±
# search_type="similarity": ìœ ì‚¬ë„ ê¸°ë°˜ ê²€ìƒ‰
# search_kwargs={"k": 3}: ìƒìœ„ 3ê°œ ê²°ê³¼ ë°˜í™˜
retriever = vectorstore.as_retriever(
    search_type="similarity",
    search_kwargs={"k": 3}
)

# í…ŒìŠ¤íŠ¸ ê²€ìƒ‰
test_query = "ìƒì„±í˜• AIì˜ ìµœì‹  ê¸°ìˆ  ë™í–¥ì€?"
retrieved_docs = retriever.invoke(test_query)

print(f"ê²€ìƒ‰ê¸° ìƒì„± ì™„ë£Œ")
print(f"í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬: '{test_query}'")
print(f"ê²€ìƒ‰ëœ ë¬¸ì„œ: {len(retrieved_docs)}ê°œ")
print(f"ì²« ë²ˆì§¸ ê²°ê³¼: {retrieved_docs[0].page_content[:100]}...")

# ============================================================
# 6ë‹¨ê³„: í”„ë¡¬í”„íŠ¸ (Prompt) - ë©€í‹°í„´ ëŒ€í™”ìš©
# - ê²€ìƒ‰ëœ ì •ë³´ì™€ ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ ë°”íƒ•ìœ¼ë¡œ LLMì„ ìœ„í•œ ì§ˆë¬¸ êµ¬ì„±
# ============================================================
print("\n[6ë‹¨ê³„] í”„ë¡¬í”„íŠ¸ (Prompt) - ë©€í‹°í„´")
print("-" * 80)

# ë©€í‹°í„´ RAG í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ êµ¬ì„±
# {context}: ê²€ìƒ‰ëœ ë¬¸ì„œë“¤
# {chat_history}: ì´ì „ ëŒ€í™” ë‚´ì—­
# {question}: í˜„ì¬ ì‚¬ìš©ì ì§ˆë¬¸
prompt_template = ChatPromptTemplate.from_messages([
    ("system", """ë‹¹ì‹ ì€ AI ê¸°ìˆ  ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì•„ë˜ ì œê³µëœ ë¬¸ë§¥(context)ê³¼ ì´ì „ ëŒ€í™” ë‚´ì—­ì„ **ë°˜ë“œì‹œ ì°¸ê³ **í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.

ì¤‘ìš”:
1. ì´ì „ ëŒ€í™” ë‚´ìš©ì„ ê¸°ì–µí•˜ê³  ì—°ê´€ì§€ì–´ ë‹µë³€í•˜ì„¸ìš”.
2. ë¬¸ë§¥ì— ê´€ë ¨ ë‚´ìš©ì´ ìˆìœ¼ë©´ ê·¸ê²ƒì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.
3. ë¬¸ë§¥ì— ì—†ëŠ” ë‚´ìš©ë§Œ "ì œê³µëœ ë¬¸ì„œì—ì„œ í•´ë‹¹ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ë‹µë³€í•˜ì„¸ìš”.
4. ë‹µë³€ ì‹œ ë¬¸ë§¥ì˜ ì–´ëŠ ë¶€ë¶„ì„ ì°¸ê³ í–ˆëŠ”ì§€ ëª…ì‹œí•˜ì„¸ìš”.
5. "ê·¸ê²ƒ", "ê·¸ê±°", "ì €ê²ƒ" ë“±ì˜ ëŒ€ëª…ì‚¬ëŠ” ì´ì „ ëŒ€í™”ë¥¼ ì°¸ê³ í•˜ì—¬ êµ¬ì²´ì ìœ¼ë¡œ í•´ì„í•˜ì„¸ìš”.

ë¬¸ë§¥:
{context}
"""),
    MessagesPlaceholder(variable_name="chat_history"),  # ëŒ€í™” íˆìŠ¤í† ë¦¬
    ("human", "{question}")
])

print("ë©€í‹°í„´ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„± ì™„ë£Œ")
print(f"ì‹œìŠ¤í…œ ì—­í• : AI ê¸°ìˆ  ì „ë¬¸ê°€ (ëŒ€í™” ê¸°ì–µ ê¸°ëŠ¥)")
print(f"í”„ë¡¬í”„íŠ¸ êµ¬ì¡°: ë¬¸ë§¥(context) + ëŒ€í™” íˆìŠ¤í† ë¦¬(chat_history) + ì§ˆë¬¸(question)")

# ============================================================
# 7ë‹¨ê³„: LLM (Large Language Model)
# - êµ¬ì„±ëœ í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹µë³€ ìƒì„±
# ============================================================
print("\n[7ë‹¨ê³„] LLM (Large Language Model)")
print("-" * 80)

# ChatGPT ëª¨ë¸ ì´ˆê¸°í™”
llm = ChatOpenAI(
    model="gpt-4o-mini",  # ëª¨ë¸ ì„ íƒ
    temperature=0.5,      # ì°½ì˜ì„± ì¡°ì ˆ (0=ê²°ì •ì , 1=ì°½ì˜ì )
)

print("LLM ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ")
print(f"ëª¨ë¸: gpt-4o-mini")

# ============================================================
# 8ë‹¨ê³„: ì²´ì¸(Chain) ìƒì„± - ë©€í‹°í„´ ëŒ€í™”ìš©
# - ëª¨ë“  ê³¼ì •ì„ í•˜ë‚˜ì˜ íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ ì—°ê²°
# - ëŒ€í™” íˆìŠ¤í† ë¦¬ ê´€ë¦¬ ê¸°ëŠ¥ ì¶”ê°€
# ============================================================
print("\n[8ë‹¨ê³„] ì²´ì¸(Chain) ìƒì„± - ë©€í‹°í„´")
print("-" * 80)

# ë¬¸ì„œë¥¼ ë¬¸ë§¥ìœ¼ë¡œ í¬ë§·íŒ…í•˜ëŠ” í•¨ìˆ˜
def format_docs(docs):
    """
    ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì„ ë²ˆí˜¸ì™€ êµ¬ë¶„ì„ ìœ¼ë¡œ í¬ë§·íŒ…
    - [ë¬¸ì„œ 1], [ë¬¸ì„œ 2] í˜•ì‹ìœ¼ë¡œ ë²ˆí˜¸ ë¶€ì—¬
    - --- êµ¬ë¶„ì„ ìœ¼ë¡œ ëª…í™•í•˜ê²Œ ë¶„ë¦¬
    """
    formatted = []
    for idx, doc in enumerate(docs, 1):
        formatted.append(f"[ë¬¸ì„œ {idx}]\n{doc.page_content}")
    return "\n\n---\n\n".join(formatted)

# RAG Chain êµ¬ì„± (ë©€í‹°í„´ ì§€ì›)
# itemgetter = ë”•ì…”ë„ˆë¦¬ë‚˜ ë¦¬ìŠ¤íŠ¸ì—ì„œ íŠ¹ì • í‚¤/ì¸ë±ìŠ¤ì˜ ê°’ì„ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜
rag_chain = (
    {
        "context": itemgetter("question") | retriever | format_docs,
        "question": itemgetter("question"),
        "chat_history": itemgetter("chat_history")  # ëŒ€í™” íˆìŠ¤í† ë¦¬ ì „ë‹¬
    }
    | prompt_template   # í”„ë¡¬í”„íŠ¸ ìƒì„±
    | llm               # LLM ì‹¤í–‰
    | StrOutputParser() # ì¶œë ¥ íŒŒì‹±
)

# ============================================================
# ëŒ€í™” íˆìŠ¤í† ë¦¬ ê´€ë¦¬
# - ì„¸ì…˜ë³„ë¡œ ëŒ€í™” ë‚´ì—­ì„ ì €ì¥í•˜ê³  ê´€ë¦¬
# ============================================================

# ì„¸ì…˜ë³„ ëŒ€í™” íˆìŠ¤í† ë¦¬ ì €ì¥ì†Œ
# ë”•ì…”ë„ˆë¦¬ë¡œ ì—¬ëŸ¬ ì‚¬ìš©ì/ì„¸ì…˜ì˜ ëŒ€í™”ë¥¼ ë¶„ë¦¬í•˜ì—¬ ê´€ë¦¬
store = {}

def get_session_history(session_id: str) -> BaseChatMessageHistory:
    """
    ì„¸ì…˜ IDë¡œ ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ ê°€ì ¸ì˜¤ê±°ë‚˜ ìƒˆë¡œ ìƒì„±
    
    Args:
        session_id: ì„¸ì…˜ êµ¬ë¶„ ID (ì˜ˆ: "user123")
    
    Returns:
        í•´ë‹¹ ì„¸ì…˜ì˜ ëŒ€í™” íˆìŠ¤í† ë¦¬ ê°ì²´
    """
    if session_id not in store:
        store[session_id] = InMemoryChatMessageHistory()
    return store[session_id]

# RunnableWithMessageHistoryë¡œ ëŒ€í™” íˆìŠ¤í† ë¦¬ ê´€ë¦¬ ê¸°ëŠ¥ ì¶”ê°€
conversational_rag_chain = RunnableWithMessageHistory(
    rag_chain,                          # ê¸°ë³¸ RAG ì²´ì¸
    get_session_history,                # ì„¸ì…˜ íˆìŠ¤í† ë¦¬ ì¡°íšŒ í•¨ìˆ˜
    input_messages_key="question",      # ì‚¬ìš©ì ì…ë ¥ í‚¤
    history_messages_key="chat_history" # íˆìŠ¤í† ë¦¬ í‚¤ (í”„ë¡¬í”„íŠ¸ì˜ MessagesPlaceholderì™€ ì¼ì¹˜)
)

print("ë©€í‹°í„´ RAG Chain ìƒì„± ì™„ë£Œ")
print("""
ğŸ“Š Chain êµ¬ì¡° (ë©€í‹°í„´):
   ì§ˆë¬¸ ì…ë ¥
      â†“
   [ëŒ€í™” íˆìŠ¤í† ë¦¬ ë¡œë“œ] ì´ì „ ëŒ€í™” ë‚´ìš© ë¶ˆëŸ¬ì˜¤ê¸°
      â†“
   [Retriever] ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰ (5ë‹¨ê³„)
      â†“
   [Format] ë¬¸ì„œë¥¼ ë¬¸ë§¥ìœ¼ë¡œ ë³€í™˜
      â†“
   [Prompt] í”„ë¡¬í”„íŠ¸ ìƒì„± (ë¬¸ë§¥ + íˆìŠ¤í† ë¦¬ + ì§ˆë¬¸)
      â†“
   [LLM] ë‹µë³€ ìƒì„± (7ë‹¨ê³„)
      â†“
   [ëŒ€í™” íˆìŠ¤í† ë¦¬ ì €ì¥] ì§ˆë¬¸ê³¼ ë‹µë³€ ì €ì¥
      â†“
   ìµœì¢… ë‹µë³€ ì¶œë ¥
""")

# ============================================================
# RAG ì‹¤í–‰ í…ŒìŠ¤íŠ¸ - ë©€í‹°í„´ ëŒ€í™”
# ============================================================
print("\n" + "=" * 80)
print("RAG ì‹œìŠ¤í…œ ì‹¤í–‰ í…ŒìŠ¤íŠ¸ - ë©€í‹°í„´ ëŒ€í™”")
print("=" * 80)

# ì„¸ì…˜ ID (ì‚¬ìš©ì êµ¬ë¶„ìš©)
session_id = "user_test_001"

# ì—°ì†ëœ ì§ˆë¬¸ë“¤ (ë¬¸ë§¥ ìœ ì§€ í…ŒìŠ¤íŠ¸)
conversation_questions = [
    "ì¤‘êµ­ êµ­ë¬´ì›ì´ ë°œí‘œí•œ 'AI í”ŒëŸ¬ìŠ¤' ì •ì±…ì˜ 3ë‹¨ê³„ ì¤‘ì¥ê¸° ëª©í‘œëŠ” ë¬´ì—‡ì´ë©°, 6ëŒ€ í•µì‹¬ ì˜ì—­ì€ ì–´ë””ì¸ê°€ìš”?",
    "ê·¸ ì •ì±…ì—ì„œ ê°€ì¥ ì¤‘ìš”í•˜ê²Œ ë‹¤ë£¨ëŠ” ì‚°ì—… ë¶„ì•¼ëŠ” ë¬´ì—‡ì¸ê°€ìš”?",
    "í•´ë‹¹ ì •ì±…ì˜ ì˜ˆìƒ ê²½ì œ íš¨ê³¼ë‚˜ ëª©í‘œ ìˆ˜ì¹˜ê°€ ìˆë‚˜ìš”?",
    "êµ¬ê¸€ì´ ê³µê°œí•œ ì´ë¯¸ì§€ í¸ì§‘ ëª¨ë¸ 'ì œë¯¸ë‚˜ì´ 2.5 í”Œë˜ì‹œ ì´ë¯¸ì§€'ì˜ ê°€ì¥ í° íŠ¹ì§•ì€ ë¬´ì—‡ì¸ê°€ìš”?",
    "ì´ ëª¨ë¸ì€ ì–´ë–¤ ê¸°ìˆ ì„ ê¸°ë°˜ìœ¼ë¡œ ë§Œë“¤ì–´ì¡Œë‚˜ìš”?",
    "ê¸°ì¡´ ì´ë¯¸ì§€ í¸ì§‘ ëª¨ë¸ê³¼ ë¹„êµí–ˆì„ ë•Œ ì–´ë–¤ ì¥ì ì´ ìˆë‚˜ìš”?",
    "ìŠ¤íƒ í¬ë“œ ëŒ€í•™ì˜ ì—°êµ¬ ê²°ê³¼, ìƒì„± AIì˜ í™•ì‚°ì´ ê²½ë ¥ ì´ˆê¸° ê·¼ë¡œìì˜ ê³ ìš©ì— ì–´ë–¤ ì˜í–¥ì„ ë¯¸ì¹˜ê³  ìˆë‚˜ìš”?",
    "êµ¬ì²´ì ìœ¼ë¡œ ì–´ë–¤ ì§ì¢…ì´ë‚˜ ì§ë¬´ì—ì„œ ê°€ì¥ í° ì˜í–¥ì„ ë°›ê³  ìˆë‚˜ìš”?",
    "ì´ëŸ¬í•œ ì˜í–¥ì— ëŒ€í•œ í•´ê²°ì±…ì´ë‚˜ ëŒ€ì‘ ë°©ì•ˆì´ ì œì‹œë˜ì—ˆë‚˜ìš”?",
]

print(f"\nì„¸ì…˜ ID: {session_id}")
print(f"ì—°ì†ëœ ëŒ€í™”ë¥¼ í†µí•´ ë¬¸ë§¥ ìœ ì§€ í…ŒìŠ¤íŠ¸\n")

for idx, question in enumerate(conversation_questions, 1):
    print(f"\n{'=' * 80}")
    print(f"[í„´ {idx}] ì‚¬ìš©ì: {question}")
    print("-" * 80)
    
    # ë©€í‹°í„´ RAG Chain ì‹¤í–‰
    # configì— session_idë¥¼ ì „ë‹¬í•˜ì—¬ ëŒ€í™” íˆìŠ¤í† ë¦¬ ê´€ë¦¬
    answer = conversational_rag_chain.invoke(
        {"question": question},
        config={"configurable": {"session_id": session_id}}
    )
    
    print(f"AI: {answer}")

# ============================================================
# ëŒ€í™” íˆìŠ¤í† ë¦¬ í™•ì¸
# ============================================================
print("\n" + "=" * 80)
print("ëŒ€í™” íˆìŠ¤í† ë¦¬ í™•ì¸")
print("=" * 80)

# ì €ì¥ëœ ëŒ€í™” ë‚´ì—­ ì¶œë ¥
history = store[session_id]
print(f"\nì´ ë©”ì‹œì§€ ìˆ˜: {len(history.messages)}ê°œ")
print("\nëŒ€í™” ë‚´ì—­:")
for idx, message in enumerate(history.messages, 1):
    role = "ì‚¬ìš©ì" if message.type == "human" else "AI"
    print(f"\n[{idx}] {role}:")
    print(message.content[:200] + "..." if len(message.content) > 200 else message.content)


# ============================================================
# ëŒ€í™”í˜• RAG ì‹œìŠ¤í…œ - ë©€í‹°í„´
# ============================================================
print("\nëŒ€í™”í˜• RAG ì‹œìŠ¤í…œ ì‹œì‘ (ë©€í‹°í„´)")
print("ì¢…ë£Œí•˜ë ¤ë©´ 'quit' ë˜ëŠ” 'exit'ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
print("ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”: 'clear' ë˜ëŠ” 'ì´ˆê¸°í™”'")
print("=" * 80)

# ì´ˆê¸°í™” ì‹œ ìƒˆë¡œìš´ ì„¸ì…˜ ì‹œì‘
user_session_id = "interactive_user"

while True:
    user_question = input("\nì§ˆë¬¸: ").strip()
    
    # ì¢…ë£Œ ëª…ë ¹
    if user_question.lower() in ['quit', 'exit', 'ì¢…ë£Œ']:
        print("\nRAG ì‹œìŠ¤í…œì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        break
    
    # ëŒ€í™” ì´ˆê¸°í™” ëª…ë ¹
    if user_question.lower() in ['clear', 'ì´ˆê¸°í™”']:
        if user_session_id in store:
            store[user_session_id] = InMemoryChatMessageHistory()
        print("ëŒ€í™” ê¸°ë¡ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
        continue
    
    # ë¹ˆ ì…ë ¥ ì²´í¬
    if not user_question:
        print("ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        continue
    
    try:
        print("\në¬¸ì„œ ê²€ìƒ‰ ì¤‘...")
        
        # ë©€í‹°í„´ RAG Chain ì‹¤í–‰
        answer = conversational_rag_chain.invoke(
            {"question": user_question},
            config={"configurable": {"session_id": user_session_id}}
        )
        
        print(f"\nAI: {answer}")
        print("-" * 80)
        
    except Exception as e:
        print(f"\nì—ëŸ¬ ë°œìƒ: {e}")