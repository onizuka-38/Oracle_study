# COPYRIGHT 2025 (C) WYHIL. ALL RIGHTS RESERVED
# crux:PLATFORM | CONFIDENTIAL crux:ACADEMY

import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin
import re

BASE = "https://finance.naver.com"

HEADERS = {
    "User-Agent": (
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
        "AppleWebKit/537.36 (KHTML, like Gecko) "
        "Chrome/120.0.0.0 Safari/537.36"
    )
}

def get_soup(url: str) -> BeautifulSoup:
    r = requests.get(url, headers=HEADERS, timeout=10)
    r.raise_for_status()
    # ë„¤ì´ë²„ëŠ” ì£¼ë¡œ euc-kr. íƒì§€ ì‹¤íŒ¨ ëŒ€ë¹„ fallback
    r.encoding = r.apparent_encoding or "euc-kr"
    if "euc" not in (r.encoding or "").lower():
        r.encoding = "euc-kr"
    return BeautifulSoup(r.text, "html.parser")

# ------------------ 1) ë‰´ìŠ¤: href íŒ¨í„´ ê¸°ë°˜ ------------------
def extract_news(soup: BeautifulSoup, limit=10):
    items = []
    # ìš°ì„ : hrefì— news_read í¬í•¨ëœ ë§í¬(ë„¤ì´ë²„ ê¸ˆìœµ ë‰´ìŠ¤ ë³¸ë¬¸)
    for a in soup.select('a[href*="news_read"]'):
        title = a.get_text(strip=True)
        href = urljoin(BASE, a.get("href", ""))
        if title and href not in {h for _, h in items}:
            items.append((title, href))
            if len(items) >= limit:
                break
    # í›„ë³´ê°€ ì—†ìœ¼ë©´ ë„“ê²Œ: "news"ê°€ í´ë˜ìŠ¤/ì•„ì´ë””ì— í¬í•¨ëœ ì»¨í…Œì´ë„ˆ ë‚´ë¶€ ë§í¬
    if not items:
        for a in soup.select('[class*="news"] a, [id*="news"] a'):
            title = a.get_text(strip=True)
            href = urljoin(BASE, a.get("href", ""))
            if title and "news" in href and href not in {h for _, h in items}:
                items.append((title, href))
                if len(items) >= limit:
                    break
    return items

# ------------------ 2) ì¸ê¸° ì¢…ëª©: ì¢…ëª© ìƒì„¸ URL íŒ¨í„´ ------------------
def extract_popular_stocks(soup: BeautifulSoup, limit=10):
    names = []
    for a in soup.select('a[href*="/item/main.naver?code="]'):
        t = a.get_text(strip=True)
        if t and t not in names:
            names.append(t)
        if len(names) >= limit:
            break
    # ì—†ìœ¼ë©´ aside ì˜ì—­ ì¶”ì • fallback (í´ë˜ìŠ¤ëª… ë³€í™” ëŒ€ë¹„)
    if not names:
        for a in soup.select('[class*="popular"] a, [id*="popular"] a'):
            t = a.get_text(strip=True)
            if t and t not in names:
                names.append(t)
            if len(names) >= limit:
                break
    return names

# ------------------ 3) í™˜ìœ¨: ë©”ì¸ ì‹¤íŒ¨ ì‹œ marketindex í˜ì´ì§€ë¡œ ëŒ€ì²´ ------------------
def extract_exchange(limit=6):
    # ë©”ì¸ì—ì„œ ì‹œë„
    soup = get_soup(BASE)
    rows = []
    for tr in soup.select('[class*="exchange"] tbody tr, [id*="exchange"] tbody tr'):
        tds = [td.get_text(strip=True) for td in tr.select('td')]
        if len(tds) >= 2:
            rows.append((tds[0], tds[1]))
        if len(rows) >= limit:
            break
    if rows:
        return rows

    # fallback: ì „ìš© í˜ì´ì§€ (êµ¬ì¡°ê°€ í›¨ì”¬ ì•ˆì •ì )
    mkt = get_soup("https://finance.naver.com/marketindex/exchangeList.naver")
    for tr in mkt.select("table tbody tr"):
        name = tr.select_one("td.tit a")
        price = tr.select_one("td.sale")
        if name and price:
            rows.append((name.get_text(strip=True), price.get_text(strip=True)))
        if len(rows) >= limit:
            break
    return rows

if __name__ == "__main__":
    soup = get_soup(BASE)

    print("ğŸ“¢ [ë‰´ìŠ¤ ìƒìœ„]")
    for title, href in extract_news(soup, limit=8):
        print("-", title, "->", href)

    print("\nğŸ“ˆ [ì¸ê¸° ì¢…ëª© ì¶”ì •]")
    for n in extract_popular_stocks(soup, limit=10):
        print("-", n)

    print("\nğŸ’± [í™˜ìœ¨]")
    for cur, price in extract_exchange(limit=8):
        print(f"{cur}: {price}")
